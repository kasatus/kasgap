{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import isnan\n",
    "\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from dateutil.parser import parse as dateparser\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from drivendata_validator import DrivenDataValidator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if earlier than 1999 year (there is 1900 and 1899) return -1, else return number \n",
    "# of days since 1999-1-1\n",
    "def transform_date(date):\n",
    "    if pd.isnull(date):\n",
    "        return date\n",
    "    else:\n",
    "        try:\n",
    "            pivot = dateparser('1999-1-1', dayfirst=False)\n",
    "            current = dateparser(date, dayfirst=False)\n",
    "            if current.year < 1999:\n",
    "                return -1\n",
    "            else:\n",
    "                delta = current - pivot\n",
    "                return delta.days\n",
    "        except Exception as inst:\n",
    "            print 'Exception: ' + str(date)\n",
    "            print type(inst)\n",
    "            print inst.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exporting training data\n",
    "path = '/Users/tgaponov/Desktop/cisco/kasgap/'\n",
    "train_data = path + 'data/challenge_set.tsv'\n",
    "\n",
    "train_data = pd.read_csv(train_data, delimiter='\\t')\n",
    "\n",
    "#renaming columns in training data\n",
    "old = list(train_data)\n",
    "new = [x.split('.')[1] for x in old]\n",
    "mapper = dict(zip(old, new))\n",
    "\n",
    "train_data.rename(columns=mapper, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# exporting testing data\n",
    "test_data = path + 'data/scoring_set.tsv'\n",
    "test_data = pd.read_csv(test_data, delimiter='\\t')\n",
    "\n",
    "#renaming columns in testing data\n",
    "old = list(test_data)\n",
    "new = [x.split('.')[1] for x in old]\n",
    "mapper = dict(zip(old, new))\n",
    "\n",
    "test_data.rename(columns=mapper, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a column should have 60 % and more not null entries\n",
    "thresh = int(len(train_data)*0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.loc[:, (train_data != train_data.iloc[0]).any()] \n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "train_data = train_data.dropna(axis=1, thresh=thresh)\n",
    "# dropping rows where renewed_yorn is NaN\n",
    "renewed_nan = pd.isna(train_data['renewed_yorn'])\n",
    "train_data = train_data[~renewed_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# date columns in training set\n",
    "dates_columns = [x for x in list(train_data) if 'date' in x]\n",
    "train_data[dates_columns] = train_data[dates_columns].applymap(transform_date)\n",
    "# getting all dates columns\n",
    "#dates = list(data[dates_columns].stack().reset_index()[0])\n",
    "#dates = [dateparser(x) for x in dates]\n",
    "train_data['contract_line_duration'] = \\\n",
    "                        train_data['contract_line_end_date'] - \\\n",
    "                        train_data['contract_line_start_date']\n",
    "train_data['warranty_contract_line_duration'] = \\\n",
    "                        train_data['warranty_contract_line_end_date'] - \\\n",
    "                        train_data['warranty_contract_line_start_date']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# date columns in testing set\n",
    "test_data[dates_columns] = test_data[dates_columns].applymap(transform_date)\n",
    "\n",
    "test_data['contract_line_duration'] = \\\n",
    "                        test_data['contract_line_end_date'] - \\\n",
    "                        test_data['contract_line_start_date']\n",
    "test_data['warranty_contract_line_duration'] = \\\n",
    "                        test_data['warranty_contract_line_end_date'] - \\\n",
    "                        test_data['warranty_contract_line_start_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "features_list += ['contract_line_duration', 'warranty_contract_line_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yes - no columns\n",
    "yorn_columns = [x for x in list(train_data) if 'yorn' in x]\n",
    "\n",
    "# missing values\n",
    "train_data[yorn_columns] = train_data[yorn_columns].fillna('?')\n",
    "\n",
    "yorn_encoder = LabelEncoder()\n",
    "yorn_encoder.fit([\"Y\", \"N\", \"=\", '?'])\n",
    "    \n",
    "train_data[yorn_columns] = train_data[yorn_columns] \\\n",
    "                        .apply(lambda x: yorn_encoder.transform(x))\n",
    "    \n",
    "features_list += yorn_columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_data[yorn_columns] = test_data[yorn_columns].fillna('?')\n",
    "test_data[yorn_columns] = test_data[yorn_columns] \\\n",
    "                        .apply(lambda x: yorn_encoder.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical columns\n",
    "num_columns = ['PRODUCT_TRANSACTION_TYPE',\n",
    "'CONTRACT_LINE_DURATION_IN_DAYS',\n",
    "'SERVICE_CONTRACT_DISCOUNT_PERCENTAGE',\n",
    "'CONTRACT_LINE_REACTION_TIME_CODE',\n",
    "'SALES_HIERARCHY_LEVEL',\n",
    "'SERVICE_SALES_NODE_BASE_SALES_HIERARCHY_LEVEL',\n",
    "'SERVICE_FEE_AMOUNT',\n",
    "'MAPPED_SERVICE_LIST_PRICE',\n",
    "'SERVICE_PRODUCT_BASE_SERVICE_FEE_AMOUNT',\n",
    "'SERVICE_PRODUCT_BASE_MAPPED_SERVICE_LIST_PRICE',\n",
    "'CONTRACT_LINE_NET_USD_AMOUNT',\n",
    "'PRODUCT_NET_PRICE',\n",
    "'SERVICE_PARTNER_INSTALLED_BASE_PARTNER_RENEWAL_RATE',\n",
    "'SERVICE_SALES_NODE_INSTALLED_BASE_SALES_NODE_RENEWAL_RATE',\n",
    "'PRODUCT_RENEWAL_RATE',\n",
    "'PARTNER_RENEWAL_RATE',\n",
    "'CUSTOMER_RENEWAL_RATE',\n",
    "'SALES_NODE_RENEWAL_RATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [x.lower() for x in num_columns]\n",
    "num_columns = [x for x in num_columns if x in list(train_data)]\n",
    "features_list += num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_features = [x for x in list(train_data) if (x not in features_list) \\\n",
    "                         and ('key' not in x) and ('id' not in x) and ('date' not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining columns\n",
    "train_data[remaining_features] = train_data[remaining_features].fillna('?')\n",
    "\n",
    "# initialize encoders\n",
    "enc_dict = defaultdict(LabelEncoder)\n",
    "\n",
    "for c in remaining_features:\n",
    "    enc_dict[c].fit(train_data[c])\n",
    "    #enc_dict[c].fit(train_data[c].append(test_data[c], ignore_index=True))\n",
    "\n",
    "train_data[remaining_features] = train_data[remaining_features] \\\n",
    "                        .apply(lambda x: enc_dict[x.name].transform(x))\n",
    "    \n",
    "features_list += remaining_features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_data[remaining_features] = test_data[remaining_features].fillna('?')\n",
    "test_data[remaining_features] = test_data[remaining_features] \\\n",
    "                        .apply(lambda x: enc_dict[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxs = train_data.groupby(by='instance_id', as_index=True)['contract_line_end_date'].idxmax()\n",
    "train_data_subset = train_data.loc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = list(set(features_list))\n",
    "final_train_dataset = train_data_subset[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "X = final_train_dataset.loc[:, final_train_dataset.columns != 'renewed_yorn']\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "X_ = imp.fit_transform(X)\n",
    "\n",
    "y = final_train_dataset['renewed_yorn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15829546625032995"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making the final predictions\n",
    "final_test_dataset = test_data[features_list]\n",
    "final_test_dataset = final_test_dataset.loc[:, final_test_dataset.columns != 'renewed_yorn']\n",
    "X = imp.transform(final_test_dataset)\n",
    "y_pred = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = [x[2] for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = test_data['innovation_challenge_key']\n",
    "renewal = pd.Series(y_pred)\n",
    "\n",
    "series = [key, renewal]\n",
    "cols = ['INNOVATION_CHALLENGE_KEY', 'RENEWAL_PROBABLIITY']\n",
    "submission = pd.concat(series, axis=1)\n",
    "submission.columns = cols\n",
    "\n",
    "submission.sort_values(by='INNOVATION_CHALLENGE_KEY', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sub_simple.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DrivenDataValidator()\n",
    "v.is_valid(path+'data/submissionFormat03092018.csv', 'sub_simple.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
